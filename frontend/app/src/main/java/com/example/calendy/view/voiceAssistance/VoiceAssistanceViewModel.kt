package com.example.calendy.view.voiceAssistance

import android.content.Context
import android.content.Intent
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.util.Log
import androidx.lifecycle.ViewModel
import com.example.calendy.data.maindb.category.ICategoryRepository
import com.example.calendy.data.maindb.history.IHistoryRepository
import com.example.calendy.data.maindb.message.IMessageRepository
import com.example.calendy.data.maindb.plan.IPlanRepository
import com.example.calendy.data.network.CalendyServerApi
import com.example.calendy.data.rawsqldb.RawSqlDatabase
import com.example.calendy.view.messageview.ManagerAI
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.flow.update


class VoiceAssistanceViewModel(
    private val planRepository: IPlanRepository,
    private val messageRepository: IMessageRepository,
    private val categoryRepository: ICategoryRepository,
    private val calendyServerApi: CalendyServerApi,
    private val rawSqlDatabase: RawSqlDatabase,
    private val historyRepository: IHistoryRepository,
) : ViewModel(){

    private val _uiState= MutableStateFlow(VoiceAssistanceUiState())
    val uiState = _uiState.asStateFlow()

    // Created when getSpeechRecognizer is called
    private var speechRecognizer: SpeechRecognizer? = null

    private val managerAi = ManagerAI(planRepository, messageRepository, categoryRepository, calendyServerApi, rawSqlDatabase, historyRepository)

    private fun resetState() {
        _uiState.update { VoiceAssistanceUiState() }
    }

    fun setUserInputText(text: String) {
        _uiState.update { uiState.value.copy(userInputText = text) }
    }

    fun sendRequest(request: String) {
        Log.d("VoiceAssistanceViewModel", "sendRequest: $request")
        managerAi.request(request)
    }
    fun startVoiceRecognition(context: Context) {
        if(_uiState.value.listenerState == VoiceAssistanceState.LISTENING) return
        // Permission is already granted

        resetState()

        // Toggle Speech Recognition

        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH)
        intent.putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE, context.packageName)
        intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ko-KR")
        intent.putExtra(
            RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM
        )
        intent.putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 1)

        getSpeechRecognizer(context).startListening(intent)

        _uiState.update { VoiceAssistanceUiState(
            userInputText = "",
            AiText = "ìº˜ë¦°ë””ê°€ ë“£ê³  ìˆì–´ìš”!",
            listenerState = VoiceAssistanceState.LISTENING
        ) }
    }

    fun stopVoiceRecognition(context: Context) {
        getSpeechRecognizer(context).stopListening()
        _uiState.update { current -> current.copy(listenerState = VoiceAssistanceState.DONE) }
    }

    // Event Listener for speech recognizer
    private val recognitionListener: RecognitionListener = object : RecognitionListener {
        private fun activateSpeechRecognition() {

        }

        private fun deactivateSpeechRecognition() {
            speechRecognizer?.cancel()
            speechRecognizer?.destroy()
            speechRecognizer = null
        }

        // ë§í•˜ê¸° ì‹œì‘í•  ì¤€ë¹„ê°€ë˜ë©´ í˜¸ì¶œ
        override fun onReadyForSpeech(params: Bundle) {
            activateSpeechRecognition()
        }

        // ë§í•˜ê¸° ì‹œì‘í–ˆì„ ë•Œ í˜¸ì¶œ
        override fun onBeginningOfSpeech() {

        }

        // ì…ë ¥ë°›ëŠ” ì†Œë¦¬ì˜ í¬ê¸°ë¥¼ ì•Œë ¤ì¤Œ
        override fun onRmsChanged(rmsdB: Float) {}

        // ë§ì„ ì‹œì‘í•˜ê³  ì¸ì‹ì´ ëœ audio streamì„ bufferì— ë‹´ëŠ”ë‹¤
        override fun onBufferReceived(buffer: ByteArray) {
            Log.d("VoiceAssistanceViewModel", "onBufferReceived: $buffer")
        }

        // ë§í•˜ê¸°ë¥¼ ì¤‘ì§€í•˜ë©´ í˜¸ì¶œ
        override fun onEndOfSpeech() {

        }

        // ì˜¤ë¥˜ ë°œìƒí–ˆì„ ë•Œ í˜¸ì¶œ
        override fun onError(error: Int) {
            val message = when (error) {
                SpeechRecognizer.ERROR_AUDIO                    -> "ì˜¤ë””ì˜¤ ì—ëŸ¬"
                SpeechRecognizer.ERROR_CLIENT                   -> "í´ë¼ì´ì–¸íŠ¸ ì—ëŸ¬"
                SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "í¼ë¯¸ì…˜ ì—†ìŒ"
                SpeechRecognizer.ERROR_NETWORK                  -> "ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬"
                SpeechRecognizer.ERROR_NETWORK_TIMEOUT          -> "ë„¤íŠ¸ì› íƒ€ì„ì•„ì›ƒ"
                SpeechRecognizer.ERROR_NO_MATCH                 -> "ì°¾ì„ ìˆ˜ ì—†ìŒ"
                SpeechRecognizer.ERROR_RECOGNIZER_BUSY          -> "RECOGNIZER ê°€ ë°”ì¨"
                SpeechRecognizer.ERROR_SERVER                   -> "ì„œë²„ê°€ ì´ìƒí•¨"
                SpeechRecognizer.ERROR_SPEECH_TIMEOUT           -> "ë§í•˜ëŠ” ì‹œê°„ì´ˆê³¼"
                else                                            -> "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ì„"
            }
            Log.d("VoiceAssistanceViewModel", "onError: $message")
            _uiState.update { current -> current.copy(AiText = "ì£„ì†¡í•´ìš”. ë¬¸ì œê°€ ìƒê¸´ ê²ƒ ê°™ì•„ìš”ğŸ˜¢", listenerState = VoiceAssistanceState.ERROR) }
            deactivateSpeechRecognition()
        }

        // ì¸ì‹ ê²°ê³¼ê°€ ì¤€ë¹„ë˜ë©´ í˜¸ì¶œ
        override fun onResults(results: Bundle) {
            val matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
            // Note: matches[1]ì€ ë” í™•ë¥ ì´ ë‚®ì€ ì¸ì‹ ê²°ê³¼ì´ë‹¤
            val text=matches?.firstOrNull() ?: ""

            _uiState.update { current -> current.copy(userInputText = text, AiText = "ì•Œê² ìŠµë‹ˆë‹¤. ì œê²Œ ë§¡ê²¨ì£¼ì„¸ìš”!ğŸ˜Š", listenerState = VoiceAssistanceState.DONE) }
            sendRequest(text)
            deactivateSpeechRecognition()
        }

        // ë¶€ë¶„ ì¸ì‹ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ë•Œ í˜¸ì¶œ
        override fun onPartialResults(partialResults: Bundle) {
            val matches = partialResults.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
            // Note: matches[1]ì€ ë” í™•ë¥ ì´ ë‚®ì€ ì¸ì‹ ê²°ê³¼ì´ë‹¤
            setUserInputText(matches?.firstOrNull() ?: "")
        }

        // í–¥í›„ ì´ë²¤íŠ¸ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´ ì˜ˆì•½
        override fun onEvent(eventType: Int, params: Bundle) {}
    }


    private fun getSpeechRecognizer(context: Context): SpeechRecognizer {
        return speechRecognizer ?: SpeechRecognizer.createSpeechRecognizer(context).apply {
            setRecognitionListener(recognitionListener)
        }.also {
            speechRecognizer = it
        }
    }

}

enum class VoiceAssistanceState {
    LISTENING,
    DONE,
    ERROR,
}